### Iterative maximization {#sec-newton-raphson}

(c.f., @dobson4e, Chapter 4)

::: notes
Later,
when we are trying to find MLEs for likelihoods which we can’t easily differentiate,
we will "hill-climb" using the Newton-Raphson algorithm:
:::

$$
\begin{aligned}
\esttmp{\theta}
&\leftarrow \esttmp{\theta} + \inv{\oinff{\vec y;\esttmp{\theta}}}
\scoref{\vec y;\esttmp{\theta}}
\\ &= \esttmp{\theta} - \inv{\hessf{\vec y;\esttmp{\theta}}}
\scoref{\vec y;\esttmp{\theta}}
\end{aligned}
$$

---

::: notes
The reasoning for this algorithm is that
we can approximate the the score function near $\esttmp{\theta}$
using the first-order [Taylor polynomial](https://en.wikipedia.org/wiki/Taylor%27s_theorem):
:::

$$
\ba
\score(\th)
&\approx \score^*(\th)
\\ &\eqdef \score(\esttmp{\th}) + \hessian(\esttmp{\th})(\th - \esttmp{\th})
\ea
$$

---

::: notes
The approximate score function, $\score^*(\th)$, is a linear function of $\th$, so it is easy to solve the corresponding approximate score equation, $\score^*(\th) = 0$, for $\th$:

:::

$$
\ba
\th
&= \esttmp{\th} - \score(\esttmp{\th}) \cd \inv{\hessian(\esttmp{\th})}
\ea
$$

---

For computational simplicity, we will sometimes use
$\mathfrak{I}^{- 1}(\theta)$ in place of
$I\left( \widehat{\theta},y \right)$;
doing so is called "Fisher scoring" or the "method of scoring".
Note: 
this substitution is the opposite of 
the substitution that we are making for estimating the variance of the MLE;
this time we should technically use the observed information 
but we use the expected information instead.


---

There’s also an "empirical information matrix" (see @mclachlan2007em):

$$I_{e}(\theta,y) \eqdef \sum_{i = 1}^{n}{\ell_{i}'\ {\ell_{i}'}^{\top}} - \frac{1}{n}\ell'{\ell'}^{\top}$$

where $\ell_{i}$ is the log-likelihood of the ith observation.
Note that $\ell' = \sum_{i = 1}^{n}\ell_{i}'$.

$\frac{1}{n}I_{e}(\theta,y)$ is the sample equivalent of

$$\mathfrak{I \eqdef I(}\theta) \eqdef {Cov}\left( \ell'|\theta \right) = E[ \ell'{\ell'}^{\top} ] - E[ \ell' ]\ E[ \ell' ]^{\top}$$

$$\left\{ \mathfrak{I}_{jk} \eqdef {Cov}\left( {\ell'}_{j},{\ell'}_{k} \right) = E[ \ell_{j}'\ell_{k}' ] - E[ {\ell'}_{j} ] E[ {\ell'}_{k} ] \right\}$$

$I_{e}(\theta,y)$ is sometimes computationally easier to compute for
Newton-Raphson-type maximization algorithms.

c.f. <https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization>
